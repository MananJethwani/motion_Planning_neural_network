{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The design of this comes from here:\n",
    "http://outlace.com/Reinforcement-Learning-Part-3/\n",
    "\"\"\"\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "# Adding this per a suggestion by Tim Kelch.\n",
    "# https://medium.com/@trkelch/this-post-is-great-possibly-the-best-tutorial-explanation-ive-found-thus-far-cf78886b5378#.w473ywtbw\n",
    "\n",
    "\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "\n",
    "\n",
    "def neural_net(num_sensors, params, load=''):\n",
    "    model = Sequential()\n",
    "\n",
    "    # First layer.\n",
    "    model.add(Dense(\n",
    "        params[0], kernel_initializer='lecun_uniform', input_shape=(num_sensors,)\n",
    "    ))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Second layer.\n",
    "    model.add(Dense(params[1], kernel_initializer='lecun_uniform'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Output layer.\n",
    "    model.add(Dense(4, kernel_initializer='lecun_uniform'))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    rms = RMSprop()\n",
    "    model.compile(loss='mse', optimizer=rms)\n",
    "\n",
    "    if load:\n",
    "        model.load_weights(load)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def lstm_net(num_sensors, load=False):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        output_dim=512, input_dim=num_sensors, return_sequences=True\n",
    "    ))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(output_dim=512, input_dim=512, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(output_dim=3, input_dim=512))\n",
    "    model.add(Activation(\"linear\"))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from carGame import carGame\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "from neuralNetwork import neural_net, LossHistory\n",
    "import os.path\n",
    "import timeit\n",
    "\n",
    "NUM_INPUT = 2\n",
    "GAMMA = 0.9  # Forgetting.\n",
    "\n",
    "\n",
    "def train_net(model, params):\n",
    "\n",
    "    filename = params_to_filename(params)\n",
    "\n",
    "    observe = 1000  # Number of frames to observe before training.\n",
    "    epsilon = 1\n",
    "    train_frames = 10000  # Number of frames to play.\n",
    "    batchSize = params['batchSize']\n",
    "    buffer = params['buffer']\n",
    "\n",
    "    # Just stuff used below.\n",
    "    max_car_distance = 0\n",
    "    car_distance = 0\n",
    "    t = 0\n",
    "    data_collect = []\n",
    "    replay = []  # stores tuples of (S, A, R, S').\n",
    "\n",
    "    loss_log = []\n",
    "\n",
    "    # Create a new game instance.\n",
    "    game_state = carGame()\n",
    "\n",
    "    # Get initial state by doing nothing and getting the state.\n",
    "    _, state = game_state.update(0)\n",
    "    print(state.shape)\n",
    "\n",
    "    # Let's time it.\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    # Run the frames.\n",
    "    while t < train_frames:\n",
    "\n",
    "        t += 1\n",
    "        car_distance += 1\n",
    "\n",
    "        # Choose an action.\n",
    "        if random.random() < epsilon or t < observe:\n",
    "            action = np.random.randint(0, 3)  # random\n",
    "        else:\n",
    "            # Get Q values for each action.\n",
    "            qval = model.predict(state, batch_size=1)\n",
    "            action = (np.argmax(qval))  # best\n",
    "\n",
    "        # Take action, observe new state and get our treat.\n",
    "        reward, new_state = game_state.update(action)\n",
    "\n",
    "        # Experience replay storage.\n",
    "        replay.append((state, action, reward, new_state))\n",
    "\n",
    "        # If we're done observing, start training.\n",
    "        if t > observe:\n",
    "\n",
    "            # If we've stored enough in our buffer, pop the oldest.\n",
    "            if len(replay) > buffer:\n",
    "                replay.pop(0)\n",
    "\n",
    "            # Randomly sample our experience replay memory\n",
    "            minibatch = random.sample(replay, batchSize)\n",
    "\n",
    "            # Get training values.\n",
    "            X_train, y_train = process_minibatch(minibatch, model)\n",
    "\n",
    "            # Train the model on this batch.\n",
    "            history = LossHistory()\n",
    "            model.fit(\n",
    "                X_train, y_train, batch_size=batchSize,\n",
    "                epochs=1, verbose=0, callbacks=[history]\n",
    "            )\n",
    "            loss_log.append(history.losses)\n",
    "\n",
    "        # Update the starting state with S'.\n",
    "        state = new_state\n",
    "\n",
    "        # Decrement epsilon over time.\n",
    "        if epsilon > 0.1 and t > observe:\n",
    "            epsilon -= (1/train_frames)\n",
    "\n",
    "        # We died, so update stuff.\n",
    "        if reward == -1000:\n",
    "            print('crash reported');\n",
    "            # Log the car's distance at this T.\n",
    "            data_collect.append([t, car_distance])\n",
    "\n",
    "            # Update max.\n",
    "            if car_distance > max_car_distance:\n",
    "                max_car_distance = car_distance\n",
    "\n",
    "            # Time it.\n",
    "            tot_time = timeit.default_timer() - start_time\n",
    "            fps = car_distance / tot_time\n",
    "\n",
    "            # Output some stuff so we can watch.\n",
    "            print(\"Max: %d at %d\\tepsilon %f\\t(%d)\\t%f fps\" %\n",
    "                  (max_car_distance, t, epsilon, car_distance, fps))\n",
    "\n",
    "            # Reset.\n",
    "            car_distance = 0\n",
    "            start_time = timeit.default_timer()\n",
    "\n",
    "        # Save the model every 25,000 frames.\n",
    "        if t % 250 == 0:\n",
    "            model.save_weights('saved-models/' + filename + '-' +\n",
    "                               str(t) + '.h5',\n",
    "                               overwrite=True)\n",
    "            print(\"Saving model %s - %d\" % (filename, t))\n",
    "\n",
    "    # Log results after we're done all frames.\n",
    "    log_results(filename, data_collect, loss_log)\n",
    "\n",
    "\n",
    "def log_results(filename, data_collect, loss_log):\n",
    "    # Save the results to a file so we can graph it later.\n",
    "    with open('results/sonar-frames/learn_data-' + filename + '.csv', 'w') as data_dump:\n",
    "        wr = csv.writer(data_dump)\n",
    "        wr.writerows(data_collect)\n",
    "\n",
    "    with open('results/sonar-frames/loss_data-' + filename + '.csv', 'w') as lf:\n",
    "        wr = csv.writer(lf)\n",
    "        for loss_item in loss_log:\n",
    "            wr.writerow(loss_item)\n",
    "\n",
    "\n",
    "def process_minibatch(minibatch, model):\n",
    "    \"\"\"This does the heavy lifting, aka, the training. It's super jacked.\"\"\"\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    # Loop through our batch and create arrays for X and y\n",
    "    # so that we can fit our model at every step.\n",
    "    for memory in minibatch:\n",
    "        # Get stored values.\n",
    "        old_state_m, action_m, reward_m, new_state_m = memory\n",
    "        # Get prediction on old state.\n",
    "        old_qval = model.predict(old_state_m, batch_size=1)\n",
    "        # Get prediction on new state.\n",
    "        newQ = model.predict(new_state_m, batch_size=1)\n",
    "        # Get our best move. I think?\n",
    "        maxQ = np.max(newQ)\n",
    "        y = np.zeros((1, 4))\n",
    "        y[:] = old_qval[:]\n",
    "        # Check for terminal state.\n",
    "        if reward_m != -500:  # non-terminal state\n",
    "            update = (reward_m + (GAMMA * maxQ))\n",
    "        else:  # terminal state\n",
    "            update = reward_m\n",
    "        # Update the value for the action we took.\n",
    "        y[0][action_m] = update\n",
    "        X_train.append(old_state_m.reshape(NUM_INPUT,))\n",
    "        y_train.append(y.reshape(4,))\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "\n",
    "def params_to_filename(params):\n",
    "    return str(params['nn'][0]) + '-' + str(params['nn'][1]) + '-' + \\\n",
    "            str(params['batchSize']) + '-' + str(params['buffer'])\n",
    "\n",
    "\n",
    "def launch_learn(params):\n",
    "    filename = params_to_filename(params)\n",
    "    print(\"Trying %s\" % filename)\n",
    "    # Make sure we haven't run this one.\n",
    "    if not os.path.isfile('results/sonar-frames/loss_data-' + filename + '.csv'):\n",
    "        # Create file so we don't double test when we run multiple\n",
    "        # instances of the script at the same time.\n",
    "        open('results/sonar-frames/loss_data-' + filename + '.csv', 'a').close()\n",
    "        print(\"Starting test.\")\n",
    "        # Train.\n",
    "        model = neural_net(NUM_INPUT, params['nn'])\n",
    "        train_net(model, params)\n",
    "    else:\n",
    "        print(\"Already tested.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    param_list = []\n",
    "    nn_params = [[256, 256],\n",
    "                 [512, 512], [1000, 1000]]\n",
    "    batchSizes = [40, 100, 400]\n",
    "    buffers = [10000, 50000]\n",
    "\n",
    "    for nn_param in nn_params:\n",
    "        for batchSize in batchSizes:\n",
    "            for buffer in buffers:\n",
    "                params = {\n",
    "                    \"batchSize\": batchSize,\n",
    "                    \"buffer\": buffer,\n",
    "                    \"nn\": nn_param\n",
    "                }\n",
    "                param_list.append(params)\n",
    "\n",
    "    for param_set in param_list:\n",
    "        launch_learn(param_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Once a model is learned, use this to play it.\n",
    "\"\"\"\n",
    "\n",
    "from carGame import carGame\n",
    "import numpy as np\n",
    "from neuralNetwork import neural_net\n",
    "\n",
    "NUM_SENSORS = 2\n",
    "\n",
    "\n",
    "def play(model):\n",
    "\n",
    "    car_distance = 0\n",
    "    game_state = carGame()\n",
    "\n",
    "    # Do nothing to get initial.\n",
    "    _, state = game_state.update(0)\n",
    "\n",
    "    # Move.\n",
    "    while True:\n",
    "        car_distance += 1\n",
    "\n",
    "        # Choose action.\n",
    "        action = (np.argmax(model.predict(state, batch_size=1)))\n",
    "\n",
    "        # Take action.\n",
    "        _, state = game_state.update(action)\n",
    "\n",
    "        # Tell us something.\n",
    "        if car_distance % 1000 == 0:\n",
    "            print(\"Current distance: %d frames.\" % car_distance)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    saved_model = 'saved-models/164-150-100-50000-10000.h5'\n",
    "    model = neural_net(NUM_SENSORS, [164, 150], saved_model)\n",
    "    play(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
